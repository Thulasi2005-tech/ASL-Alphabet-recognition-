{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libarries\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a7cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model\n",
    "\n",
    "model = load_model('asl_better_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee944160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    img = resize(frame, (64, 64, 3))\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    if np.max(img) > 1:\n",
    "        img = img/255.0\n",
    "    prediction = model.predict(img)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48cdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"class_indices.json\", \"r\") as f:\n",
    "    class_indices = json.load(f)\n",
    "\n",
    "# Create a reverse lookup list\n",
    "index = [letter for letter, _ in sorted(class_indices.items(), key=lambda item: item[1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d294b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 574ms/step\n",
      "[[1.53995133e-11 3.69303633e-12 3.02530327e-11 1.42356456e-08\n",
      "  1.89576670e-11 1.51257197e-07 8.08227996e-14 2.93988618e-22\n",
      "  6.35072375e-16 1.49663350e-16 3.37040048e-16 9.99967098e-01\n",
      "  9.95861163e-13 2.34690880e-08 3.26284935e-05 2.90621781e-18\n",
      "  1.84479210e-16 3.56467698e-12 2.45800103e-12 3.48930875e-08\n",
      "  1.32075698e-12 1.09976689e-07 2.17640745e-14 2.36648754e-13\n",
      "  6.42035090e-13 6.20545602e-16]]\n",
      "Predicted: L, Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(r\"C:\\Users\\thula\\Documents\\Mini_Project\\Dataset\\training_set\\D\\D16.jpg\")\n",
    "data = detect(frame)\n",
    "predicted_class = index[np.argmax(data)]\n",
    "confidence = np.max(data)\n",
    "print(f\"Predicted: {predicted_class}, Confidence: {confidence:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77333ef",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a24c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbf0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f295b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad45a4f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               15745536  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                13338     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,759,770\n",
      "Trainable params: 15,759,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Press 'q' to quit.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from collections import deque\n",
    "\n",
    "# Load the trained ASL model\n",
    "model = load_model(\"asl_better_model.h5\", compile=False)\n",
    "model.summary()\n",
    "\n",
    "# Class labels\n",
    "labels = [chr(i) for i in range(65, 91)]  # 'A' to 'Z'\n",
    "prediction_buffer = deque(maxlen=5)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)  # Width\n",
    "cap.set(4, 720)   # Height\n",
    "\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # Mirror correction\n",
    "\n",
    "    # Region of Interest (ROI)\n",
    "    x1, y1, x2, y2 = 800, 100, 1100, 400\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "    # Preprocess the ROI\n",
    "    roi_resized = cv2.resize(roi, (64, 64))\n",
    "    roi_rgb = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2RGB)\n",
    "    roi_array = img_to_array(roi_rgb) / 255.0\n",
    "    roi_array = np.expand_dims(roi_array, axis=0)\n",
    "\n",
    "    # Prediction\n",
    "    #prediction = model.predict(roi_array, verbose=0)\n",
    "    # predicted_class = labels[np.argmax(prediction)]\n",
    "    #confidence = np.max(prediction) * 100\n",
    "    prediction = model.predict(roi_array, verbose=0)\n",
    "    predicted_class = labels[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "# Use only high-confidence predictions\n",
    "    if confidence > 70:\n",
    "        prediction_buffer.append(predicted_class)\n",
    "\n",
    "    # Check if most recent predictions are consistent\n",
    "        if len(prediction_buffer) == prediction_buffer.maxlen:\n",
    "            if prediction_buffer.count(predicted_class) > 3:\n",
    "                display_text = f\"Predicted: {predicted_class}\"\n",
    "            else:\n",
    "                display_text = \"Waiting for consistent prediction...\"\n",
    "        else:\n",
    "            display_text = \"Analyzing...\"\n",
    "    else:\n",
    "        display_text = \"Waiting for clearer sign...\"\n",
    "\n",
    "\n",
    "    # Display result\n",
    "    cv2.putText(frame, f\"Predicted: {predicted_class}\", (50, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "    cv2.putText(frame, f\"Confidence: {confidence:.2f}%\", (50, 140),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('ASL Real-Time Recognition', frame)\n",
    "\n",
    "    # Check for 'q' key press\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d484d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb805b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354aa97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b7fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983ac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
